{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93227412",
   "metadata": {},
   "source": [
    "# NLP REVIEW IMDB\n",
    "En la siguiente base de datos de kraggle encontramos 50000 reseñas sobre peliculas varias . el objetivo del proyecto es detectar\n",
    "de manera autamica si la resenña fue positiva o negatica\n",
    "\n",
    "link donde encontrar la base de datos :https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d147f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3124bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/54351/Desktop/Diplomatura Data science/kraggle/base de datos/IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69a8273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Utiliza train_test_split para dividir el conjunto de datos\n",
    "text_train, text_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5df021d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of text_train: <class 'pandas.core.series.Series'>\n",
      "Length of text_train: 40000\n",
      "text_train[1]:\n",
      "A wonderful little production.   The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece.   The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life.   The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of text_train: {}\".format(type(text_train)))\n",
    "print(\"Length of text_train: {}\".format(len(text_train)))\n",
    "print(\"text_train[1]:\\n{}\".format(text_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff26a6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13ea9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las etiquetas HTML \"<br />\" de los documentos en la lista text_train y reemplazamos por espacios en blanco.\n",
    "text_train = text_train.str.replace(\"<br />\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "273b6902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class (training):\n",
      "negative    20039\n",
      "positive    19961\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Samples per class (training):\\n{}\".format(y_train.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51b75fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of text_train: <class 'pandas.core.series.Series'>\n",
      "Length of text_train: 10000\n",
      "text_train[9427]:\n",
      "Not many television shows appeal to quite as many different kinds of fans like Farscape does...I know youngsters and 30/40+ years old;fans both Male and Female in as many different countries as you can think of that just adore this T.V miniseries. It has elements that can be found in almost every other show on T.V, character driven drama that could be from an Australian soap opera; yet in the same episode it has science fact & fiction that would give even the hardiest \"Trekkie\" a run for his money in the brainbender stakes! Wormhole theory, Time Travel in true equational form...Magnificent. It embraces cultures from all over the map as the possibilities are endless having multiple stars and therefore thousands of planets to choose from.  With such a broad scope; it would be expected that nothing would be able to keep up the illusion for long, but here is where \"Farscape\" really comes into it's own element...It succeeds where all others have failed, especially the likes of Star Trek (a universe with practically zero Kaos element!) They ran out of ideas pretty quickly + kept rehashing them! Over the course of 4 seasons they manage to keep the audience's attention using good continuity and constant character evolution with multiple threads to every episode with unique personal touches to camera that are specific to certain character groups within the whole. This structure allows for an extremely large area of subject matter as loyalties are forged and broken in many ways on many many issues. I happened to see the pilot (Premiere) in passing and just had to keep tuning in after that to see if Crichton would ever \"Get the girl\", after seeing them all on television I was delighted to see them available on DVD & I have to admit that it was the only thing that kept me sane whilst I had to do a 12 hour night shift and developed chronic insomnia...Farscape was the only thing to get me through those extremely long nights...  Do yourself a favour; Watch the pilot and see what I mean...  Farscape Comet\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of text_train: {}\".format(type(text_test)))\n",
    "print(\"Length of text_train: {}\".format(len(text_test)))\n",
    "print(\"text_train[9427]:\\n{}\".format(text_test[9427]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc90f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las etiquetas HTML \"<br />\" de los documentos en la lista text_train y reemplazamos por espacios en blanco.\n",
    "text_test = text_test.str.replace(\"<br />\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7b4447f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class (test):\n",
      "positive    5039\n",
      "negative    4961\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Samples per class (test):\\n{}\".format(y_test.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b0f5d4",
   "metadata": {},
   "source": [
    "# APLICAMOS BAG OF WORD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b591a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<40000x93002 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 5432523 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# Importamos y creamos una instancia de CountVectorizer y lo ajustamos a nuestros datos\n",
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17379d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 93002\n",
      "\n",
      "First 20 features:\n",
      "['00' '000' '00000000000' '00000001' '00001' '00015' '000dm' '000s' '001'\n",
      " '003830' '007' '0079' '0080' '0083' '009' '0093638' '00am' '00o' '00pm'\n",
      " '00s']\n",
      "\n",
      "Features 20010 to 20030:\n",
      "['curtailing' 'curtain' 'curtained' 'curtains' 'curtberth' 'curtin'\n",
      " 'curtis' 'curtiz' 'curtly' 'curtright' 'curvaceous' 'curve' 'curveball'\n",
      " 'curveballs' 'curved' 'curves' 'curving' 'curvy' 'curzon' 'cus']\n",
      "\n",
      "Every 2000th feature:\n",
      "['00' 'acknowledgments' 'analog' 'atlee' 'bearings' 'blush' 'buitoni'\n",
      " 'cavalcade' 'clea' 'contaminated' 'curser' 'depression' 'doctrinaire'\n",
      " 'eeeekkk' 'eur' 'fernanda' 'freaked' 'gilding' 'guinness' 'herby'\n",
      " 'hypocrites' 'intemperate' 'jouvet' 'koun' 'lieutenants' 'magnesium'\n",
      " 'meaninglessly' 'moh' 'natsu' 'octopussy' 'panders' 'piana' 'premised'\n",
      " 'racer' 'remorselessness' 'rosenbergs' 'schock' 'shin' 'sneaky' 'stardom'\n",
      " 'supervillian' 'tenuous' 'trainwreck' 'underdelivered' 'vegas' 'weißert'\n",
      " 'yasser']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names_out()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))\n",
    "print()\n",
    "print(\"First 20 features:\\n{}\".format(feature_names[:20]))\n",
    "print()\n",
    "print(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030]))\n",
    "print()\n",
    "print(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60525116",
   "metadata": {},
   "source": [
    "# APLICAMOS LOGISTIC REGRESION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51b50347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs' handle multinomial loss;\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(solver=\"newton-cg\"), X_train, y_train, cv=5)\n",
    "print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53c24cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.89\n",
      "Best parameters:  {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(solver=\"newton-cg\"), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcd4b518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90\n"
     ]
    }
   ],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print(\"{:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6fe6308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Reescalar las características según lo informativas que esperamos que sean.\n",
    "# Uno de los métodos más comunes para hacer esto es utilizando el método tf-idf\n",
    "\n",
    "pipe = make_pipeline(TfidfVectorizer(min_df=5, norm=None), LogisticRegression(solver=\"newton-cg\"))\n",
    "param_grid = {'logisticregression__C': [0.1, 1]}\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(text_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616bdfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
